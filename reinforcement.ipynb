{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKfJV0wZGqwrmc5AgvD9Ej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonalkumari05/tic_tac_toe_game/blob/main/reinforcement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "bMBp_1GA3Abd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "EMPTY = ' '\n",
        "PLAYER_X = 'X'\n",
        "PLAYER_O = 'O'\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT_FACTOR = 0.9\n",
        "EXPLORATION_PROBABILITY = 0.2\n",
        "NUM_EPISODES = 10000\n"
      ],
      "metadata": {
        "id": "u1SV5SUQ3y76"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_winner(board, player):\n",
        "    # Check rows and columns\n",
        "    for i in range(3):\n",
        "        if all(cell == player for cell in board[i]) or all(board[j][i] == player for j in range(3)):\n",
        "            return True\n",
        "\n",
        "    # Check diagonals\n",
        "    if all(board[i][i] == player for i in range(3)) or all(board[i][2 - i] == player for i in range(3)):\n",
        "        return True\n",
        "\n",
        "    # No win found\n",
        "    return False"
      ],
      "metadata": {
        "id": "XaZftV_e3y-7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_full(board):\n",
        "    # Iterate through each row and cell in the row using nested loops\n",
        "    # Check if every cell is not empty\n",
        "    return all(cell != EMPTY for row in board for cell in row)"
      ],
      "metadata": {
        "id": "dQPMjQ4s3zBx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_empty_cells(board):\n",
        "    # Use list comprehension to generate a list of empty cell coordinates\n",
        "    # Coordinates are represented as tuples (i, j) where i is the row index and j is the column index\n",
        "    return [(i, j) for i in range(3) for j in range(3) if board[i][j] == EMPTY]"
      ],
      "metadata": {
        "id": "3b1PqhFY3zEc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_state_key(board):\n",
        "    # Convert the board to a string to create a unique key for the current state\n",
        "    return str(board)\n"
      ],
      "metadata": {
        "id": "X3zms3P_3zHF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_possible_moves(board):\n",
        "    # Utilize the get_empty_cells function to obtain the list of possible moves\n",
        "    return get_empty_cells(board)\n"
      ],
      "metadata": {
        "id": "5meeUR2p3zJ1"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(board, q_values):\n",
        "    # Exploration: Randomly choose a move with a probability of EXPLORATION_PROBABILITY\n",
        "    if random.uniform(0, 1) < EXPLORATION_PROBABILITY:\n",
        "        return random.choice(get_possible_moves(board))\n",
        "    # Exploitation: Choose the move with the highest Q-value based on the current state\n",
        "    else:\n",
        "        state_key = get_state_key(board)\n",
        "        possible_moves = get_possible_moves(board)\n",
        "        # Use the max function to find the move with the highest Q-value (or default to 0 if not present)\n",
        "        return max(possible_moves, key=lambda move: q_values.get((state_key, move), 0))\n"
      ],
      "metadata": {
        "id": "Nnx_2a653zMc"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_q_values(q_values, state, action, reward, next_state):\n",
        "    # Convert the current state and action to keys\n",
        "    state_key = get_state_key(state)\n",
        "    action_key = tuple(action)\n",
        "\n",
        "    # Q-learning update rule\n",
        "    q_values[state_key, action_key] = q_values.get((state_key, action_key), 0) + \\\n",
        "        LEARNING_RATE * (reward + DISCOUNT_FACTOR * max((q_values.get((get_state_key(next_state), m), 0) for m in get_possible_moves(next_state)), default=0) -\n",
        "                        q_values.get((state_key, action_key), 0))\n"
      ],
      "metadata": {
        "id": "kRTXCYV07tFJ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_q_values(q_values):\n",
        "    # Convert tuple keys to strings for JSON serialization\n",
        "    q_values_str_keys = {str(key): value for key, value in q_values.items()}\n",
        "\n",
        "    # Write the Q-values to a JSON file with indentation for readability\n",
        "    with open('q_values.json', 'w') as file:\n",
        "        json.dump(q_values_str_keys, file, indent=2)"
      ],
      "metadata": {
        "id": "Uyf_gRrL7xFI"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_q_learning():\n",
        "    # Initialize an empty dictionary to store Q-values\n",
        "    q_values = {}\n",
        "\n",
        "    # Iterate over the specified number of episodes\n",
        "    for episode in range(NUM_EPISODES):\n",
        "        # Initialize a new empty Tic-Tac-Toe board\n",
        "        board = [[EMPTY for _ in range(3)] for _ in range(3)]\n",
        "\n",
        "        # Start the episode with Player X\n",
        "        current_player = PLAYER_X\n",
        "\n",
        "        # Continue playing until the board is full or there is a winner\n",
        "        while not is_full(board) and not is_winner(board, PLAYER_X) and not is_winner(board, PLAYER_O):\n",
        "            # Choose an action using the Q-learning agent\n",
        "            action = choose_action(board, q_values)\n",
        "\n",
        "            # Update the board with the chosen action for the current player\n",
        "            i, j = action\n",
        "            board[i][j] = current_player\n",
        "\n",
        "            # Determine the reward based on the game state\n",
        "            if is_winner(board, current_player):\n",
        "                reward = 1\n",
        "            elif is_full(board):\n",
        "                reward = 0\n",
        "            else:\n",
        "                reward = 0\n",
        "\n",
        "            # Update Q-values based on the Q-learning update rule\n",
        "            update_q_values(q_values, board, action, reward, board)\n",
        "\n",
        "            # Switch to the other player for the next move\n",
        "            current_player = PLAYER_O if current_player == PLAYER_X else PLAYER_X\n",
        "\n",
        "    # Save the learned Q-values to a JSON file\n",
        "    save_q_values(q_values)\n",
        "\n",
        "    # Return the learned Q-values\n",
        "    return q_values"
      ],
      "metadata": {
        "id": "ypnVTU7b4GrC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_q_values = train_q_learning()"
      ],
      "metadata": {
        "id": "Vq-lEVED4SZp"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(board, q_values):\n",
        "    # Convert the current state to a string key\n",
        "    state_key = str(board)\n",
        "\n",
        "    # Get a list of possible moves (empty cells)\n",
        "    possible_moves = get_empty_cells(board)\n",
        "\n",
        "    # Choose the move with the highest Q-value based on the current state\n",
        "    return max(possible_moves, key=lambda move: q_values.get((state_key, move), 0))\n"
      ],
      "metadata": {
        "id": "BUzLSceB_GCm"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def human_move(board):\n",
        "    while True:\n",
        "        try:\n",
        "            # Prompt the user to enter the row and column\n",
        "            row = int(input(\"Enter the row (0, 1, or 2): \"))\n",
        "            col = int(input(\"Enter the column (0, 1, or 2): \"))\n",
        "\n",
        "            # Check if the selected cell is empty\n",
        "            if board[row][col] == EMPTY:\n",
        "                return row, col\n",
        "            else:\n",
        "                print(\"Cell is already occupied. Try again.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n"
      ],
      "metadata": {
        "id": "LnPnjvfJ4wUg"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_board(board):\n",
        "    for row in board:\n",
        "        # Print each row with cell values separated by '|'\n",
        "        print('|'.join(row))\n",
        "        # Print a line of dashes to separate rows\n",
        "        print('-' * 5)\n"
      ],
      "metadata": {
        "id": "9K_vRynV47Qg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_q_values(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        # Use the json.load function to read Q-values from the file\n",
        "        return json.load(file)\n"
      ],
      "metadata": {
        "id": "ZNzSh_Rg47YF"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def play_game(q_values):\n",
        "    board = [[EMPTY for _ in range(3)] for _ in range(3)]\n",
        "\n",
        "    while True:\n",
        "        print_board(board)\n",
        "\n",
        "        # Human player's move\n",
        "        human_row, human_col = human_move(board)\n",
        "        board[human_row][human_col] = PLAYER_X\n",
        "\n",
        "        if is_winner(board, PLAYER_X):\n",
        "            print_board(board)\n",
        "            print(\"Congratulations! You win!\")\n",
        "            break\n",
        "        elif is_full(board):\n",
        "            print_board(board)\n",
        "            print(\"It's a tie!\")\n",
        "            break\n",
        "\n",
        "        # AI's move\n",
        "        print(\"AI's turn:\")\n",
        "        ai_row, ai_col = choose_action(board, q_values)\n",
        "        board[ai_row][ai_col] = PLAYER_O\n",
        "\n",
        "        if is_winner(board, PLAYER_O):\n",
        "            print_board(board)\n",
        "            print(\"AI wins! Better luck next time.\")\n",
        "            break\n",
        "        elif is_full(board):\n",
        "            print_board(board)\n",
        "            print(\"It's a tie!\")\n",
        "            break"
      ],
      "metadata": {
        "id": "Jmvyvhqi47am"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Q-values from the JSON file\n",
        "q_values = load_q_values('q_values.json')\n",
        "\n",
        "# Start the game\n",
        "play_game(q_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oQGoj2p47eE",
        "outputId": "00eda4fc-212b-4642-ee89-adf9d446ba07"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | | \n",
            "-----\n",
            " | | \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Enter the row (0, 1, or 2): 0\n",
            "Enter the column (0, 1, or 2): 0\n",
            "AI's turn:\n",
            "X|O| \n",
            "-----\n",
            " | | \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Enter the row (0, 1, or 2): 1\n",
            "Enter the column (0, 1, or 2): 1\n",
            "AI's turn:\n",
            "X|O|O\n",
            "-----\n",
            " |X| \n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Enter the row (0, 1, or 2): 1\n",
            "Enter the column (0, 1, or 2): 0\n",
            "AI's turn:\n",
            "X|O|O\n",
            "-----\n",
            "X|X|O\n",
            "-----\n",
            " | | \n",
            "-----\n",
            "Enter the row (0, 1, or 2): 2\n",
            "Enter the column (0, 1, or 2): 0\n",
            "X|O|O\n",
            "-----\n",
            "X|X|O\n",
            "-----\n",
            "X| | \n",
            "-----\n",
            "Congratulations! You win!\n"
          ]
        }
      ]
    }
  ]
}